{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trump Tweet Bot (Keras)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The lab_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext lab_black\n"
     ]
    }
   ],
   "source": [
    "%load_ext lab_black\n",
    "import sys, random, os, gc, re, json\n",
    "from string import punctuation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Input, Dense\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "\n",
    "from eda_func import tweet_cleaner, rmv_uncommon\n",
    "from bot_func import DataGenerator, TextCorpus, one_hot_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"./data/archive.json\"\n",
    "\n",
    "df = pd.read_json(DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(tweet_cleaner)\n",
    "df[\"text\"] = df.text.apply(rmv_uncommon)\n",
    "# Remove tweets that just contain empty strings\n",
    "df = df[(df[\"text\"] != \"\") | (df[\"text\"] != \" \")]\n",
    "\n",
    "# Remove Retweets\n",
    "df = df[df.is_retweet == False]\n",
    "\n",
    "# Use \"special\" symbol @ to indicate end of tweet, since we removed them all before\n",
    "corpus = \"@\".join(df[\"text\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Set-up\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_bot1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 32, 256)           346112    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 256)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 256)               526336    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 80)                20560     \n",
      "=================================================================\n",
      "Total params: 893,008\n",
      "Trainable params: 893,008\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "full_corp = TextCorpus(corpus)\n",
    "\n",
    "train_corp = full_corp[: int(len(full_corp) * 0.9)]\n",
    "test_corp = full_corp[int(len(full_corp) * 0.9) :]\n",
    "\n",
    "SAMPLE_LEN = 32\n",
    "STEP_SIZE = 3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_gen = DataGenerator(train_corp, SAMPLE_LEN, STEP_SIZE)\n",
    "test_gen = DataGenerator(test_corp, SAMPLE_LEN, STEP_SIZE, shuffle=False)\n",
    "\n",
    "nchars = full_corp.get_num_chars()\n",
    "\n",
    "model = Sequential(name=\"test_bot1\")\n",
    "model.add(Input(shape=(SAMPLE_LEN, nchars), dtype=np.float32))\n",
    "model.add(CuDNNLSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(CuDNNLSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nchars, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Batch 0\n",
      "SAMPLE: I would like to wish everyone A \n",
      "TARGET: (H)\n",
      "----------------------------------------\n",
      "Batch 1\n",
      "SAMPLE: ould like to wish everyone A HAP\n",
      "TARGET: (P)\n",
      "----------------------------------------\n",
      "Batch 2\n",
      "SAMPLE: d like to wish everyone A HAPPY \n",
      "TARGET: (A)\n",
      "----------------------------------------\n",
      "Batch 3\n",
      "SAMPLE: ike to wish everyone A HAPPY AND\n",
      "TARGET: ( )\n",
      "----------------------------------------\n",
      "Batch 4\n",
      "SAMPLE:  to wish everyone A HAPPY AND HE\n",
      "TARGET: (A)\n",
      "----------------------------------------\n",
      "Batch 5\n",
      "SAMPLE:  wish everyone A HAPPY AND HEALT\n",
      "TARGET: (H)\n",
      "----------------------------------------\n",
      "Batch 6\n",
      "SAMPLE: sh everyone A HAPPY AND HEALTHY \n",
      "TARGET: (N)\n",
      "----------------------------------------\n",
      "Batch 7\n",
      "SAMPLE: everyone A HAPPY AND HEALTHY NEW\n",
      "TARGET: ( )\n",
      "----------------------------------------\n",
      "Batch 8\n",
      "SAMPLE: ryone A HAPPY AND HEALTHY NEW YE\n",
      "TARGET: (A)\n",
      "----------------------------------------\n",
      "Batch 9\n",
      "SAMPLE: ne A HAPPY AND HEALTHY NEW YEAR.\n",
      "TARGET: ( )\n",
      "----------------------------------------\n",
      "Batch 10\n",
      "SAMPLE: A HAPPY AND HEALTHY NEW YEAR. WE\n",
      "TARGET: ( )\n",
      "----------------------------------------\n",
      "Batch 11\n",
      "SAMPLE: APPY AND HEALTHY NEW YEAR. WE MU\n",
      "TARGET: (S)\n",
      "----------------------------------------\n",
      "Batch 12\n",
      "SAMPLE: Y AND HEALTHY NEW YEAR. WE MUST \n",
      "TARGET: (A)\n",
      "----------------------------------------\n",
      "Batch 13\n",
      "SAMPLE: ND HEALTHY NEW YEAR. WE MUST ALL\n",
      "TARGET: ( )\n",
      "----------------------------------------\n",
      "Batch 14\n",
      "SAMPLE: HEALTHY NEW YEAR. WE MUST ALL WO\n",
      "TARGET: (R)\n",
      "----------------------------------------\n",
      "Batch 15\n",
      "SAMPLE: LTHY NEW YEAR. WE MUST ALL WORK \n",
      "TARGET: (T)\n",
      "----------------------------------------\n",
      "Batch 16\n",
      "SAMPLE: Y NEW YEAR. WE MUST ALL WORK TOG\n",
      "TARGET: (E)\n",
      "----------------------------------------\n",
      "Batch 17\n",
      "SAMPLE: EW YEAR. WE MUST ALL WORK TOGETH\n",
      "TARGET: (E)\n",
      "----------------------------------------\n",
      "Batch 18\n",
      "SAMPLE: YEAR. WE MUST ALL WORK TOGETHER \n",
      "TARGET: (T)\n",
      "----------------------------------------\n",
      "Batch 19\n",
      "SAMPLE: R. WE MUST ALL WORK TOGETHER TO,\n",
      "TARGET: ( )\n",
      "----------------------------------------\n",
      "Batch 20\n",
      "SAMPLE: WE MUST ALL WORK TOGETHER TO, FI\n",
      "TARGET: (N)\n",
      "----------------------------------------\n",
      "Batch 21\n",
      "SAMPLE: MUST ALL WORK TOGETHER TO, FINAL\n",
      "TARGET: (L)\n",
      "----------------------------------------\n",
      "Batch 22\n",
      "SAMPLE: T ALL WORK TOGETHER TO, FINALLY,\n",
      "TARGET: ( )\n",
      "----------------------------------------\n",
      "Batch 23\n",
      "SAMPLE: LL WORK TOGETHER TO, FINALLY, MA\n",
      "TARGET: (K)\n",
      "----------------------------------------\n",
      "Batch 24\n",
      "SAMPLE: WORK TOGETHER TO, FINALLY, MAKE \n",
      "TARGET: (A)\n",
      "----------------------------------------\n",
      "Batch 25\n",
      "SAMPLE: K TOGETHER TO, FINALLY, MAKE AME\n",
      "TARGET: (R)\n",
      "----------------------------------------\n",
      "Batch 26\n",
      "SAMPLE: OGETHER TO, FINALLY, MAKE AMERIC\n",
      "TARGET: (A)\n",
      "----------------------------------------\n",
      "Batch 27\n",
      "SAMPLE: THER TO, FINALLY, MAKE AMERICA S\n",
      "TARGET: (A)\n",
      "----------------------------------------\n",
      "Batch 28\n",
      "SAMPLE: R TO, FINALLY, MAKE AMERICA SAFE\n",
      "TARGET: ( )\n",
      "----------------------------------------\n",
      "Batch 29\n",
      "SAMPLE: O, FINALLY, MAKE AMERICA SAFE AG\n",
      "TARGET: (A)\n",
      "----------------------------------------\n",
      "Batch 30\n",
      "SAMPLE: FINALLY, MAKE AMERICA SAFE AGAIN\n",
      "TARGET: ( )\n",
      "----------------------------------------\n",
      "Batch 31\n",
      "SAMPLE: ALLY, MAKE AMERICA SAFE AGAIN AN\n",
      "TARGET: (D)\n"
     ]
    }
   ],
   "source": [
    "def decode(arr, corp):\n",
    "\n",
    "    for batch in range(arr[0].shape[0]):\n",
    "        print(\"-\" * 40)\n",
    "        print(\"Batch \" + str(batch))\n",
    "        string = \"\"\n",
    "        sample = arr[0][batch, ...]\n",
    "        for letter in sample:\n",
    "            string += corp.indicies_to_char[np.where(letter == 1)[0][0]]\n",
    "        ans = corp.indicies_to_char[np.where(arr[1][batch] == 1)[0][0]]\n",
    "        print(\"SAMPLE:\", string)\n",
    "        print(\"TARGET: ({})\".format(ans))\n",
    "\n",
    "\n",
    "decode(train_gen[0], full_corp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an Predict\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Epoch 1\n"
     ]
    }
   ],
   "source": [
    "tweet_ends = np.where(np.asarray(list(corpus)) == \"@\")[0]\n",
    "\n",
    "for epoch in range(1, 31):\n",
    "    print('-' * 40)\n",
    "    print('Epoch', epoch)\n",
    "    model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=train_gen.epoch_size,\n",
    "        epochs=1,\n",
    "        validation_data=test_gen,\n",
    "        validation_steps=test_gen.epoch_size)\n",
    "    \n",
    "    seed_index = 1 + np.random.choice(tweet_ends, 1)[0]\n",
    "    for diversity in [0.2, 0.7, 1.2]:\n",
    "        genertate_tweet(model, seed_index, diversity, full_corp)\n",
    "    print('-' * 40)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
