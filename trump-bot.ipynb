{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trump Tweet Bot (Keras)\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black\n",
    "import sys, random, os, gc, re, json\n",
    "from string import punctuation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Input, Dense\n",
    "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
    "\n",
    "from eda_func import tweet_cleaner\n",
    "from bot_func import DataGenerator, TextCorpus, one_hot_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"./data/archive.json\"\n",
    "\n",
    "df = pd.read_json(DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].apply(tweet_cleaner)\n",
    "\n",
    "# Remove tweets that just contain empty strings\n",
    "df = df[(df[\"text\"] != \"\") | (df[\"text\"] != \" \")]\n",
    "\n",
    "# Remove Retweets\n",
    "df = df[df.is_retweet == False]\n",
    "\n",
    "# Use \"special\" symbol @ to indicate end of tweet, since we removed them all before\n",
    "corpus = \"@\".join(df[\"text\"].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline Set-up\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"test_bot1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "cu_dnnlstm (CuDNNLSTM)       (None, 32, 256)           356352    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32, 256)           0         \n",
      "_________________________________________________________________\n",
      "cu_dnnlstm_1 (CuDNNLSTM)     (None, 256)               526336    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 90)                23130     \n",
      "=================================================================\n",
      "Total params: 905,818\n",
      "Trainable params: 905,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "full_corp = TextCorpus(corpus)\n",
    "\n",
    "train_corp = full_corp[: int(len(full_corp) * 0.9)]\n",
    "test_corp = full_corp[int(len(full_corp) * 0.9) :]\n",
    "\n",
    "SAMPLE_LEN = 32\n",
    "STEP_SIZE = 3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_gen = DataGenerator(train_corp, SAMPLE_LEN, STEP_SIZE)\n",
    "test_gen = DataGenerator(test_corp, SAMPLE_LEN, STEP_SIZE, shuffle=False)\n",
    "\n",
    "nchars = full_corp.get_num_chars()\n",
    "\n",
    "model = Sequential(name=\"test_bot1\")\n",
    "model.add(Input(shape=(SAMPLE_LEN, nchars), dtype=np.float32))\n",
    "model.add(CuDNNLSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(CuDNNLSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(nchars, activation=\"softmax\"))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\")\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train an Predict\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Epoch 1\n"
     ]
    }
   ],
   "source": [
    "tweet_ends = np.where(np.asarray(list(corpus)) == \"@\")[0]\n",
    "\n",
    "for epoch in range(1, 31):\n",
    "    print('-' * 40)\n",
    "    print('Epoch', epoch)\n",
    "    model.fit(\n",
    "        train_gen,\n",
    "        steps_per_epoch=train_gen.epoch_size,\n",
    "        epochs=1,\n",
    "        validation_data=test_gen,\n",
    "        validation_steps=test_gen.epoch_size)\n",
    "    \n",
    "    seed_index = 1 + np.random.choice(tweet_ends, 1)[0]\n",
    "    for diversity in [0.2, 0.7, 1.2]:\n",
    "        genertate_tweet(model, seed_index, diversity, full_corp)\n",
    "    print('-' * 40)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
